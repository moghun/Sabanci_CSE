{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Hw2-Neuralnet-morhun",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzUXgel6No1"
      },
      "source": [
        "# **CS412 - Machine Learning - 2022**\n",
        "## Assignment #2\n",
        "100 pts\n",
        "\n",
        "\n",
        "## Goal\n",
        "\n",
        "The goal of this homework is two-fold:\n",
        "\n",
        "*   Gain experience with neural network approaches\n",
        "*   Gain experience with the Keras library\n",
        "\n",
        "## Dataset\n",
        "You are going to use a house price dataset that we prepared for you, that contains four independent variables (predictors) and one target variable. The task is predicting the target variable (house price) from the predictors (house attributes).\n",
        "\n",
        "\n",
        "Download the data from SuCourse. Reserve 10% of the training data for validation and use the rest for development (learning your models). The official test data we provide (1,200 samples) should only be used for testing at the end, and not model selection.\n",
        "\n",
        "## Task \n",
        "Build a regressor with a neural network that has only one hidden layer, using the Keras library function calls to predict house prices in the provided dataset.\n",
        "\n",
        "Your code should follow the given skeleton and try the indicated parameters.\n",
        "\n",
        "## Preprocessing and Meta-parameters\n",
        "You should try 10,50 and 100 as hidden node count. \n",
        "\n",
        "You should  decide on the learning rate (step size), you can try values such as 0.001, 0.01, 0.1, but you may need to increase if learning is very slow or decrease if you see the loss increase!\n",
        "\n",
        "You can use either sigmoid or Relu activations for the hidden nodes (indicate with your results) and you should know what to use for the activation for the output layer, input, output layer sizes, and the suitable loss function. \n",
        "\n",
        "## Software: \n",
        "\n",
        "Keras is a library that we will use especially for deep learning, but also with basic neural network functionality of course.\n",
        "\n",
        "You may find the necessary function references here: \n",
        "\n",
        "http://scikit-learn.org/stable/supervised_learning.html\n",
        "https://keras.io/api/\n",
        "\n",
        "When you search for Dense for instance, you should find the relevant function and explained parameters, easily.\n",
        "\n",
        "## Submission: \n",
        "\n",
        "Fill this notebook. Write the report section at the end.\n",
        "\n",
        "You should prepare a separate pdf document as your homework (name hw2-CS412-yourname.pdf) which consists of the report (Part 8) of the notebook for easy viewing -and- include a link to your notebook from within the pdf report (make sure to include the link obtained from the #share link on top right, **be sure to share with SabancÄ± University first** as otherwise there will be access problems.). Also, do not forget to add your answers for Questions 2 and 3 on the assignment document."
      ],
      "id": "vMzUXgel6No1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBtSa7Pc8tCn"
      },
      "source": [
        "##1) Initialize\n",
        "\n",
        "*   First make a copy of the notebook given to you as a starter.\n",
        "\n",
        "*   Make sure you choose Connect form upper right.\n"
      ],
      "id": "cBtSa7Pc8tCn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFNmGxqa9G2O"
      },
      "source": [
        "## 2) Load training dataset\n",
        "\n",
        "* Load the datasets (train.csv, test.csv) provided on SuCourse on your Google drive and read the datasets using Google Drive's mount functions. \n",
        "You may find the necessary functions here: \n",
        "https://colab.research.google.com/notebooks/io.ipynb"
      ],
      "id": "hFNmGxqa9G2O"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nza2i-JK92eu",
        "outputId": "65393958-76ed-41c2-96dc-a32cc12991d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') \n",
        "# click on the url that pops up and give the necessary authorizations"
      ],
      "id": "nza2i-JK92eu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9P--030AOoK"
      },
      "source": [
        "\n",
        "\n",
        "*   Set your notebooks working directory to the path where the datasets are uploaded (cd is the linux command for change directory) \n",
        "*   You may need to use cd drive/MyDrive depending on your path to the datasets on Google Drive. (don't comment the code in the cells when using linux commands)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "s9P--030AOoK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lplqod5D_cf1",
        "outputId": "5dbc6fd6-3a1d-481d-ffa4-7501141b4552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd drive/MyDrive/CS412_Assignmet2/"
      ],
      "id": "lplqod5D_cf1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS412_Assignmet2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfMT3IgEAugF"
      },
      "source": [
        "* List the files in the current directory."
      ],
      "id": "IfMT3IgEAugF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoopxfoX-VOq",
        "outputId": "ce23daad-79e2-481a-cb6e-41e2dd68b5e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls "
      ],
      "id": "aoopxfoX-VOq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.csv  train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZh3Y5AlBHAs"
      },
      "source": [
        "##3) Understanding the dataset (5 pts)\n",
        "\n",
        "There are alot of functions that can be used to know more about this dataset\n",
        "\n",
        "- What is the shape of the training set (num of samples X number of attributes) **[shape function can be used]**\n",
        "\n",
        "- Display attribute names **[columns function can be used]**\n",
        "\n",
        "- Display the first 5 rows from training dataset **[head or sample functions can be used]**\n",
        "\n",
        ".."
      ],
      "id": "fZh3Y5AlBHAs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "658e2be2",
        "outputId": "99e0d4b3-eb05-47f8-a0cc-4fadc4153a7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import the necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# show first 10 elements of the training data\n",
        "print(train_df.head(10))\n",
        "print(\"\\n\")"
      ],
      "id": "658e2be2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sqmtrs  nrooms   view crime_rate          price\n",
            "0     251       5   west        low  925701.721399\n",
            "1     211       3   west       high  622237.482636\n",
            "2     128       5   east        low  694998.182376\n",
            "3     178       3   east       high  564689.015926\n",
            "4     231       3   west        low  811222.970379\n",
            "5     253       5  north       high  766250.032506\n",
            "6     101       1  north        low  512749.401548\n",
            "7     242       1  north       high  637010.760148\n",
            "8     174       5   west       high  638136.374869\n",
            "9     328       2  south       high  787704.988273\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12bbf0c6",
        "outputId": "c83a0967-6bab-4d6d-e1b7-838e1500eeaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# print the shape of data\n",
        "print(\"Data dimensionality is: \")\n",
        "print(train_df.shape)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "print(\"Unique valus for categorical data: \")\n",
        "print(\"view: \" + train_df['view'].unique())\n",
        "print(\"crime_rate: \" + train_df['crime_rate'].unique())\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# also give some statistics about the data like mean, standard deviation etc.\n",
        "print(\"Numerical data statistics: \")\n",
        "print(train_df.describe())\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"View Mode: \")\n",
        "print(train_df['view'].mode())\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Crime Rate Mode: \")\n",
        "print(train_df['crime_rate'].mode())\n",
        "print(\"\\n\")\n"
      ],
      "id": "12bbf0c6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dimensionality is: \n",
            "(4800, 5)\n",
            "\n",
            "\n",
            "Unique valus for categorical data: \n",
            "['view: west' 'view: east' 'view: north' 'view: south']\n",
            "['crime_rate: low' 'crime_rate: high']\n",
            "\n",
            "\n",
            "Numerical data statistics: \n",
            "            sqmtrs       nrooms         price\n",
            "count  4800.000000  4800.000000  4.800000e+03\n",
            "mean    225.033542     2.983958  7.257570e+05\n",
            "std      71.851436     1.421251  1.510411e+05\n",
            "min     100.000000     1.000000  3.564985e+05\n",
            "25%     163.000000     2.000000  6.179536e+05\n",
            "50%     226.000000     3.000000  7.292999e+05\n",
            "75%     287.000000     4.000000  8.389284e+05\n",
            "max     349.000000     5.000000  1.076067e+06\n",
            "\n",
            "\n",
            "View Mode: \n",
            "0    east\n",
            "dtype: object\n",
            "\n",
            "\n",
            "Crime Rate Mode: \n",
            "0    high\n",
            "dtype: object\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtBJzQ6NB1Kz"
      },
      "source": [
        "##4) Preprocessing Steps (10 pts)\n",
        "\n",
        "As some of the features (predictive variables) on this dataset are categorical (non-numeric) you need to do some preprocessing for those features.\n",
        "\n",
        "You can use as many **dummy or indicator variables** as there are categories within one feature. You can also look at pandas' get_dummies or keras.utils.to_categorical functions.\n",
        "\n",
        "In neural networks, scaling of the features are important, because they affect the net input of a neuron as a whole. You should use **MinMax scaler** on sklearn for this task, which scales the variables between 0 and 1 on by default. (Remember that mean-squared error loss function tends to be extremely large with unscaled features.)\n"
      ],
      "id": "GtBJzQ6NB1Kz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b505bf7b"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "train_df = pd.get_dummies(train_df)\n",
        "\n",
        "# scale the features between 0-1\n",
        "msc = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "scaled = msc.fit_transform(train_df)\n",
        "\n",
        "scaled_df = pd.DataFrame(scaled, columns=train_df.columns.values)\n",
        "\n",
        "# Define X:\n",
        "X = scaled_df.drop(columns=['price'])\n",
        "\n",
        "# Define y:\n",
        "y = scaled_df[['price']]\n"
      ],
      "id": "b505bf7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnSUvg-OK9FP"
      },
      "source": [
        "Don't forget the split the training data to obtain a validation set. **Use random_state=42**"
      ],
      "id": "nnSUvg-OK9FP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WufovdxNK8sI",
        "outputId": "85ed4231-c352-46f0-d5d0-1e544b2345f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# split 90-10\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "print(X_train.shape, X_validate.shape, y_train.shape,y_validate.shape)"
      ],
      "id": "WufovdxNK8sI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4320, 8) (480, 8) (4320, 1) (480, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU-_nQ4IFuR3"
      },
      "source": [
        "##5) Train neural networks on development data and do model selection using the validation data (55 pts)\n",
        "\n",
        "\n",
        "* Train a neural network with **one hidden layer** (try 3 different values for the number of neurons in that hidden layer, as 25, 50, 100), you will need to correctly choose the optimizer and the loss function that this model will train with. Use batch_size as 64 and train each model for 30 epochs. \n",
        "\n",
        "* Train another neural network with two hidden layers with meta-parameters of your choice. Again, use batch_size as 64 and train the model for 30 epochs. \n",
        "\n",
        "* **Bonus (5 pts)** Train a KNN or a Decision Tree model with your own choice of meta parameters to predict the house prices.\n"
      ],
      "id": "hU-_nQ4IFuR3"
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.utils\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "AQYmU5mK0j2v"
      },
      "id": "AQYmU5mK0j2v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NN w/ 1 Hidden Layer"
      ],
      "metadata": {
        "id": "KrS0eB4a-PPU"
      },
      "id": "KrS0eB4a-PPU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bec4fb64"
      },
      "source": [
        "from keras import models\n",
        "# train one-hidden layered neural networks\n",
        "# define your model architecture\n",
        "\n",
        "# Creates a NN with given layer size and activation function architecture then compiles it with given learning rate\n",
        "def nn_oneHid(layer1, learning_rate, activation):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(Flatten())\n",
        "  model.add(tf.keras.layers.Dense(layer1, activation=activation, input_shape = (X_train.shape[1],), name='hidden_layer_1'))\n",
        "  model.add(tf.keras.layers.Dense(1, name='output_layer'))\n",
        "\n",
        "  model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate = learning_rate))\n",
        "  fit_model = model.fit(X_train, y_train, batch_size = 64, epochs = 30, verbose=1)\n",
        "\n",
        "  return model"
      ],
      "id": "bec4fb64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "V7381WyJ-oHN"
      },
      "id": "V7381WyJ-oHN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvsgI7rWI1ST",
        "outputId": "dd1cf178-a731-4306-d834-5c54565b2a81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "activations = ['sigmoid', 'relu']\n",
        "learning_rate = [0.001, 0.01, 0.1]\n",
        "layer = [25, 50, 100]\n",
        "\n",
        "models = []\n",
        "one_layered = {}\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(activations)):\n",
        "  print(\"Activation: \", activations[i], \"\\n\")\n",
        "  for j in range(len(learning_rate)):\n",
        "    print(\"Learning Rate: \", learning_rate[j], \"\\n\")\n",
        "    for k in range(len(layer)):\n",
        "      print(\"Nodes in Layer: \", layer[k], \"\\n\")\n",
        "      model = nn_oneHid(layer[k], learning_rate[j], activations[i])\n",
        "      models.append(model)\n",
        "      one_layered[model] = {'model': model, 'activation': activations[i], 'layer1': layer[k], 'learning_rate': learning_rate[j]}\n",
        "\n",
        "\n"
      ],
      "id": "rvsgI7rWI1ST",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation:  sigmoid \n",
            "\n",
            "Learning Rate:  0.001 \n",
            "\n",
            "Nodes in Layer:  25 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0269\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0175\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0111\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0038\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0020\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 6.4235e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.5683e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.8756e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6971e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5862e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6080e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6097e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5832e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6393e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6009e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5978e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6187e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5965e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 3.5861e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 3.5896e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5614e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5945e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5768e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5590e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5905e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.7022e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6120e-04\n",
            "Nodes in Layer:  50 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0438\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0211\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0118\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0062\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0030\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 7.2091e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.6921e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8469e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6582e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6243e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6133e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6198e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6155e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6144e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6085e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6434e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5827e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6289e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6387e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6189e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6174e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6989e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6301e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5983e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6170e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6712e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6509e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6075e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6417e-04\n",
            "Nodes in Layer:  100 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.2188\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0261\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0168\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0119\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0087\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0062\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0042\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0029\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.5009e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1907e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.8817e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2038e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8494e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6830e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6156e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5662e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5377e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5826e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5492e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5468e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5522e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5625e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5419e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5390e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5594e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5532e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5966e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 3.5801e-04\n",
            "Learning Rate:  0.01 \n",
            "\n",
            "Nodes in Layer:  25 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0343\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0020\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.9496e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.8158e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.7739e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.8196e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.9001e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8007e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.9209e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1161e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.3666e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.8322e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.7127e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.7297e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.1128e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7259e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.9346e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.8454e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6918e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6882e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.8012e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6419e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.4440e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.6107e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5706e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5361e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.5890e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6978e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7821e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.1681e-04\n",
            "Nodes in Layer:  50 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0197\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5518e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6294e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6916e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8495e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9100e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7944e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7367e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9017e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.9218e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9504e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.8545e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.4360e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.0228e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.0180e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3894e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.2490e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1297e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1342e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0790e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8906e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9251e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1180e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.2267e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3127e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7537e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.1208e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2098e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.3032e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2383e-04\n",
            "Nodes in Layer:  100 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0233\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.3739e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.2396e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.2084e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 4.2405e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 4.2210e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 4.5078e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 4.6049e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 4.6837e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 5.0040e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 4.8706e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.3881e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 6.4661e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 5.3766e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 4.5136e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.2595e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.5567e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.3178e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.9598e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.6103e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.1669e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.2566e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.7050e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.6910e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.5547e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 6.6413e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 4.3492e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 8.2820e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 7.7236e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 6.1605e-04\n",
            "Learning Rate:  0.1 \n",
            "\n",
            "Nodes in Layer:  25 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 3ms/step - loss: 0.1353\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4354e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 4.1317e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 3.8060e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 3.6054e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 3.3002e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.1021e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.0013e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.9483e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 2.7334e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6631e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 2.6042e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 2.4186e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 2.3503e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 2.2648e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 2.2549e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 2.1633e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.1828e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.0425e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1909e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1800e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.2246e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0127e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 1.9156e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.9426e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.9951e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 1.8249e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.7531e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 1.7255e-04\n",
            "Nodes in Layer:  50 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 2s 5ms/step - loss: 0.4865\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0122\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.3345e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 4.4809e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.2172e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.1263e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 4.0061e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.8302e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 3.5769e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 3.4717e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 3.4854e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1847e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.0809e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9990e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8630e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7692e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.8976e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.5248e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 2.5036e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6397e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.3926e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2551e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0940e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.1311e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0193e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.9356e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.8065e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.7542e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.6178e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.6380e-04\n",
            "Nodes in Layer:  100 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 3ms/step - loss: 0.9941\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0284\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0069\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.0344e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.4754e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.0669e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.6314e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.2418e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.0274e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.5875e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.2828e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.9562e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.7694e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5440e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.3625e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.2247e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.9423e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.6770e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.5209e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.3465e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.1927e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.0423e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 3.0503e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.8505e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.8305e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.5686e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5456e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5139e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4136e-04\n",
            "Activation:  relu \n",
            "\n",
            "Learning Rate:  0.001 \n",
            "\n",
            "Nodes in Layer:  25 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.7249\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0971\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0360\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0217\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0142\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0091\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0056\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0037\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0029\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0022\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0010\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 9.3936e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.7794e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 8.1372e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.6602e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.2126e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7992e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 6.4370e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 6.0605e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 5.7667e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 5.4661e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 5.1920e-04\n",
            "Nodes in Layer:  50 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0320\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0031\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.5409e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.5637e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.0724e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 2.4491e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0252e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.7410e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.5288e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3688e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2546e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1412e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0504e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 9.9619e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.4590e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.1506e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.6933e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.2769e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.2254e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9181e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.7884e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.6567e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5830e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3827e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 7.2896e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.0787e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.9423e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7028e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8398e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.5991e-05\n",
            "Nodes in Layer:  100 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0416\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.5119e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.7259e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5513e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8342e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3387e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.9765e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.7152e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.5468e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3760e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2522e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1349e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0709e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0133e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.4777e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.0587e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.7803e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.6711e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.2040e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0473e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.7959e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5019e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3714e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.2690e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.0775e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.9534e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.9359e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.9690e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7147e-05\n",
            "Learning Rate:  0.01 \n",
            "\n",
            "Nodes in Layer:  25 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0271\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3539e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7364e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4010e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 3.7967e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3111e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1179e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0061e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8447e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7537e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7231e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 2.6679e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6129e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 2.8624e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 2.6747e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4344e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4281e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5871e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7444e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 2.1894e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 2.4031e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1548e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0200e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0767e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.8811e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.8349e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 2.2682e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 1.9622e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3221e-04\n",
            "Nodes in Layer:  50 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0289\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.8460e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 2.6429e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.9744e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4666e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2264e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0876e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.5994e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.0848e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.8124e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.4768e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0932e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.2075e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0389e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 8.7161e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0359e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 8.0099e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 8.3419e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.7870e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.2869e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 7.7411e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5599e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 7.8378e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9686e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.3872e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9508e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.1025e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.5649e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.7597e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 9.1828e-05\n",
            "Nodes in Layer:  100 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7159e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4237e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0061e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.6414e-05\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.1102e-05\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8088e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.4327e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7541e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8816e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5716e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.4234e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7982e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3959e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7431e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1605e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6887e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.1381e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.5103e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8278e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.0706e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.6788e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.4735e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7145e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.0931e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3816e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.2038e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.2084e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.7778e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0039e-04\n",
            "Learning Rate:  0.1 \n",
            "\n",
            "Nodes in Layer:  25 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0651\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4194e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2371e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0531e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8813e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9540e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9772e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9133e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9976e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0746e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3258e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5617e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9223e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2718e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 1ms/step - loss: 4.1953e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1022e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5261e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9860e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9516e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0979e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1658e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3585e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9779e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5184e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5855e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.1901e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.3756e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.4101e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.1699e-04\n",
            "Nodes in Layer:  50 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.1476\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3986e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8686e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8911e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8605e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0478e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9412e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1115e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0433e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1174e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9705e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8764e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3624e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5295e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6023e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6247e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1413e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4428e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1018e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1978e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9882e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9257e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6865e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3731e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.4819e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8214e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6861e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6227e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7712e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.2177e-04\n",
            "Nodes in Layer:  100 \n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.3033\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9199e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7790e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8406e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0170e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9650e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0060e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4577e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3507e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2545e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1869e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2061e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4965e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9960e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2385e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.8332e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.6294e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2083e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6433e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4711e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.7778e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9958e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6274e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3244e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0917e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1596e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6628e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.7147e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.8443e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3134e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###NN w/ 2 Hidden Layer"
      ],
      "metadata": {
        "id": "0STz9e3l-V1b"
      },
      "id": "0STz9e3l-V1b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions that trains a two-hidden layered neural network\n",
        "\n",
        "# Creates a NN with given layer size and activation function architecture then compiles it with given learning rate\n",
        "def nn_twoHid(layer1, layer2, learning_rate, activation):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(Flatten())\n",
        "  model.add(tf.keras.layers.Dense(layer1, activation=activation, input_shape = (X_train.shape[1],), name='hidden_layer_1'))\n",
        "  model.add(tf.keras.layers.Dense(layer2, activation=activation, name='hidden_layer_2'))\n",
        "  model.add(tf.keras.layers.Dense(1, name='output_layer'))\n",
        "\n",
        "  model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate = learning_rate))\n",
        "  fit_model = model.fit(X_train, y_train, batch_size = 64, epochs = 30, verbose=1)\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "474ns5h6HAXZ"
      },
      "id": "474ns5h6HAXZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training\n"
      ],
      "metadata": {
        "id": "BxWuuIyh-c86"
      },
      "id": "BxWuuIyh-c86"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13b3d502",
        "outputId": "97c1fd71-c54b-4c18-e64d-5e00880130c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "activations = ['sigmoid', 'relu']\n",
        "learning_rate = [0.001, 0.01, 0.1]\n",
        "layer = [25, 50, 100]\n",
        "layer2 = [25, 50, 100]\n",
        "\n",
        "models_two = []\n",
        "two_layered = {}\n",
        "\n",
        "for i in range(len(activations)):\n",
        "  print(\"Activation: \", activations[i], \"\\n\")\n",
        "  for j in range(len(learning_rate)):\n",
        "    print(\"Learning Rate: \", learning_rate[j], \"\\n\")\n",
        "    for k in range(len(layer2)):\n",
        "      print(\"Nodes in Layer-2: \", layer2[k], \"\\n\")\n",
        "      for l in range(len(layer)):\n",
        "        print(\"Nodes in Layer-1: \", layer[l], \"\\n\")\n",
        "        model = nn_twoHid(layer[l], layer2[k], learning_rate[j], activations[i])\n",
        "        models_two.append(model)\n",
        "        two_layered[model] = {'model': model, 'activation': activations[i], 'layer1': layer[k], 'layer2': layer2[l],'learning_rate': learning_rate[j]}\n",
        "\n",
        "        \n",
        "# ...\n"
      ],
      "id": "13b3d502",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0367\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0254\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0169\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0100\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0047\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.2047e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9128e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6062e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5627e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5154e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5928e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6408e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5397e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5638e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5618e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5154e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4430e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5573e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5834e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5428e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5340e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5000e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4151e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4298e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4606e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4107e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4098e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3730e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3755e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.1797\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0394\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0351\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0309\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0269\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0231\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0195\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0162\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0130\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0098\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0070\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0046\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0027\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.6903e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.3750e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0227e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5003e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3175e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2600e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2478e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2450e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2288e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2274e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2260e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2294e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2168e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2072e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1944e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2095e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0521\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0273\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0183\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0112\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9478e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1367e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5151e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4618e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3975e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3739e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3942e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3693e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3763e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4259e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4803e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3662e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4605e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3476e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4738e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5494e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5204e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6143e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7040e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6038e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4265e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7188e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4120e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4281e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.1659\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0402\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0369\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0336\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0301\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0265\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0226\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0188\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0151\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0117\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0084\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0033\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.6064e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.6833e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0731e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5035e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3152e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2610e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2846e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2436e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2258e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2189e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2579e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1915e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2005e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2088e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1729e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1812e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0433\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0290\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0185\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0100\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0041\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.7783e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.4644e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5218e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3740e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.4656e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.5018e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.4249e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4497e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.4317e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.4900e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.3986e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5165e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.3903e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.4047e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.4016e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.4885e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.7888e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.4654e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.4669e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5658e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.8246e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.5003e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8111e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7165e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0359\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0212\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0114\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0043\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1741e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4580e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6350e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6667e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7423e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5443e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5136e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6785e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6334e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7605e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6767e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1845e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4885e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4266e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8502e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0236e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9687e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7557e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6193e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7404e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5905e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6677e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9881e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9092e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6560e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0478\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0330\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0235\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0154\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0087\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0037\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.1093e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7976e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7207e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7370e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7292e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6879e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6848e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6235e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5350e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6312e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7506e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5032e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6349e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6215e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5664e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4697e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5084e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3811e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8017e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5765e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5900e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4727e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4682e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0609\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0352\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0254\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0171\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0100\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0045\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3369e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7488e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4528e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5025e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5048e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5129e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5009e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4155e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6034e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5034e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6261e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4377e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5663e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5185e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4316e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4638e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5060e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9490e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5022e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9492e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5737e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5317e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7497e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0402\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0222\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0109\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0035\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3938e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7416e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6130e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7411e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7287e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9498e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5856e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7755e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0498e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2373e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7942e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9466e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0697e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0890e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8097e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3524e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6942e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0762e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5538e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0852e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0358e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9906e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0416e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2798e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4328e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.7894e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0601\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.2597e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5059e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4175e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3383e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4104e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4542e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4234e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9962e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0300e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0791e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9567e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8617e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8846e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6690e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6071e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4965e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6222e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5893e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5964e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9836e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6375e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7910e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8099e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5892e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4204e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7192e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4684e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2308e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0837\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0132\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3526e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4604e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3902e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3346e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4199e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1497e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2222e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1019e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1485e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9651e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1436e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0682e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2958e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7406e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7096e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8617e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3499e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9684e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6117e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8971e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8403e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0723e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7794e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3436e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2729e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6249e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5930e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0338\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4817e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5499e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7684e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5011e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4363e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5737e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0194e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.8716e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6712e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4304e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7345e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3226e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0612e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3274e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6085e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0087e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6895e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4621e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3174e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3134e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5904e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4486e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3102e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0518e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.8995e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1244e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.5824e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.6555e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.1250\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0198\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0045\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3442e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6027e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5228e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5341e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6613e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3425e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3172e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3365e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3231e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1992e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1504e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0910e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0629e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2248e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2142e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8038e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9972e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8420e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7868e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7302e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6804e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5443e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5591e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6342e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3819e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2403e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2499e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.1407\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0170\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0036\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2104e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4541e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4392e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4874e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4975e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3915e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4124e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3805e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5017e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3986e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3465e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3584e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6201e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4586e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1657e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0411e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2717e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3382e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4899e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4112e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3427e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9843e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0716e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2037e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8422e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2403e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0715e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.1218\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0127\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8897e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7641e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0094e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8566e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7246e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6252e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7341e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6856e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6166e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4761e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5891e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8898e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9844e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6553e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4619e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7780e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1901e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9818e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1673e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9398e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4457e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2675e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7913e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1154e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1489e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4440e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8031e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0577\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0039\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7958e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8305e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1691e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8732e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9424e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.1317e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0414e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7789e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0651e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8280e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5606e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.4396e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3481e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4938e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5707e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5915e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2635e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7603e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0227e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9581e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9490e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3966e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3951e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.0063e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7805e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.9801e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.0705e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.8241e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.1567\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0174\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0024\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3583e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4111e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3249e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4696e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3187e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4553e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2674e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9620e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4663e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8858e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7801e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9416e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6365e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1230e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3259e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3697e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0211e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1207e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2420e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9859e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8120e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1493e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1846e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4623e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4321e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3073e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1191e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.2099\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0163\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0033\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9982e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4680e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5678e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5339e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5201e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5526e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6553e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3559e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3986e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5176e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4298e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.5028e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5698e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5554e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2730e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2945e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3763e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.6245e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1842e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1967e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.0407e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5859e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7037e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3923e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9332e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3254e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3076e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.1684\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0081\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.0484e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0318e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4519e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3740e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9783e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9509e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0116e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5853e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3548e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4350e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3824e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2633e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4254e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3361e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3705e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5166e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8213e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1627e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3594e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4097e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4307e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2858e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2669e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1471e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1629e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1217e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1148e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.7765e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.4083\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0302\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0029\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5861e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.2696e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4734e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7506e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1815e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6036e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1733e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.7367e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3930e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1109e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.9391e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9945e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.8763e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.6335e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.4885e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0536e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.4673e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0721e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1534e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2202e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.5754e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0075e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5043e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.7856e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.3352e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2268e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9276e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.7335\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0441\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0441\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0441\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0444\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0441\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0449\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0128\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0035\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0028\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.8682e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.1624e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.3475e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.7044e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2635e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3482e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4080e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1851e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0296e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6423e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.0195e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2047e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1678e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2337e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0007e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8979e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.5668\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0084\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.4016e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0398e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8836e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1686e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.5728e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9534e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6095e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0697e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7675e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3314e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0334e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7877e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6451e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5749e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4915e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4184e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3840e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3573e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4260e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2398e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3467e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3101e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5185e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2425e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3356e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3820e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.5721\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0037\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0191e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.5727e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.3911e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5133e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9970e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7735e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3663e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2082e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8576e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6018e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4807e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2843e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3632e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.8108e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4863e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3988e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2585e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1809e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4364e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0407e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4336e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2166e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2617e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1331e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3147e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3424e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.5892e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 1.8849\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0422\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0169\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0058\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0040\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0029\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0027\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.7844e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.9083e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.4283e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.2373e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8626e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.3484e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6298e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.2882e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0427e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.2248e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.8040e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6367e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0669e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6697e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8936e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0189e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6819e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0516e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 1.4258\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0210\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0060\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0022\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0010\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.9092e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5572e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6932e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1628e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.6627e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.3689e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.8953e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5635e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2339e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0951e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7414e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5163e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2832e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1584e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9784e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9279e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7338e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6731e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.5854e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4982e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4849e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6262e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 2.0915\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0305\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0042\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.4848e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7784e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.2649e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.8559e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4220e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2882e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0868e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.7790e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4860e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3211e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0501e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.9617e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7955e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4774e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3445e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3052e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0331e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1154e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0304e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.8744e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.7818e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.6047e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.5212e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3765e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2593e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1798e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1460e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 3.6657\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0459\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0444\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0409\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0187\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0036\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0027\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0032\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.3481e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.0423e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.4345e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.4736e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5227e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.6346e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0853e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.5384e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.3628e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.0081e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.3864e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5045e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.3009\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0131\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0033\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.4412e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.1195e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.5850e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6183e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0168e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.5494e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1961e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.8788e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.6182e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.3471e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1465e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.9503e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.8116e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.6605e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.5489e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4377e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3346e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2529e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1823e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1367e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0902e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0337e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.9633e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.8232e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.3553e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.1523e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0479\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9319e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9444e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.7038e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0262e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.6241e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4123e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2259e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1112e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0444e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.7927e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.4063e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.7248e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.5970e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0983e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0088e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9066e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9180e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.7755e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.4236e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.6960e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.0738e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5895e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.0781e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.0519e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.0177e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.2721e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7996e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8401e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0215\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8759e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1273e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.9857e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4004e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1285e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.8449e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.5762e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.8430e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3834e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8886e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6448e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.4571e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.2655e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.2270e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0559e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0446e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8683e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7484e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7454e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9774e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8107e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7463e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9940e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7498e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8612e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8189e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7958e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.5189e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3686e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0717\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.9984e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.9273e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3492e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.4974e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.9309e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.6116e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3497e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1578e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0320e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.4554e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.8475e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.2031e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0485e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5363e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.4472e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.1510e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8686e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8413e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.5442e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3831e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3917e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1758e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.2395e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.2779e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.4738e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9587e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9434e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9295e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0407\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.0925e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2398e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.6630e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3297e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1427e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0117e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.9289e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.4857e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.7574e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3632e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.0261e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8146e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6455e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.5000e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3602e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.2503e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1735e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0449e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1036e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0938e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8381e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8602e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7229e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7458e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.6447e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7643e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.5657e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.6027e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0259\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.4647e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.2486e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.1772e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4900e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1564e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.8031e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.6562e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.6886e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.1873e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7804e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6473e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3071e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3294e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0714e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.4524e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8646e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8938e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0055e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0315e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9834e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6293e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9229e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0009e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8497e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7868e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7025e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9053e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.6103e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1209e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0558\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0026\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0266e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.0542e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0857e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.6519e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4547e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3091e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1531e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0896e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0019e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.3472e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.9384e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.4961e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.3081e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.8895e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.6724e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3273e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.1539e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3381e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7611e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6690e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.5942e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8777e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.9294e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6355e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3939e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6040e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.5117e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6210e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0484\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.3059e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.8513e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2805e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.8914e-05\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.6385e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.3347e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.6044e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.1276e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8154e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.8389e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.6008e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.4855e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.3752e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3212e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1387e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3920e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9662e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8959e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9866e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1457e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9594e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0684e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8897e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1862e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9092e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7735e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.6834e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7004e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0175\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.5811e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.4613e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0420e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.5159e-05\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.6436e-05\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.9906e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.5598e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.3145e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.3187e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.9166e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9062e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.1596e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.1837e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.4625e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.2345e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.1700e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.5212e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8900e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.9392e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.8397e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.1108e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.3214e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.0373e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.6431e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.0892e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.2799e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.9371e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.9839e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.6187e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0615\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.0430e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4028e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.7497e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.2665e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0119e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.9260e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.7177e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.6913e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.5095e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4591e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.5126e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.4384e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.2398e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1976e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1298e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.2559e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.1230e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 1.0878e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 1.1759e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.3081e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0024e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.5579e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 1.0757e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.8257e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 9.8517e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 9.5519e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 8.2885e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.3010e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 4ms/step - loss: 0.0116\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.5720e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.4366e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.0989e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 9.3764e-05\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.2762e-05\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.1003e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.3008e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9678e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5951e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.6172e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.4620e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.4568e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.1652e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.9614e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.0792e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.2535e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.2672e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0170e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0244e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1431e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.6304e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.7029e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3600e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1715e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3036e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1391e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3038e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1909e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.7227e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0090\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.8135e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.9485e-05\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0255e-05\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.7516e-05\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.8503e-05\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3413e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.5208e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.3224e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5441e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.2662e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.1469e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.0275e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.1008e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.0717e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.0911e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.9236e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0307e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.9618e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.0466e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.6448e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.0797e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.4146e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.1892e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.1418e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.1729e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 7.9194e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.3542e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.9909e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 1.1061e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 3ms/step - loss: 0.0165\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.8334e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.2024e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.8372e-05\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.7090e-05\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.8102e-05\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.0402e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 9.2368e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.1969e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.9950e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.2664e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.0746e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.5632e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.1501e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.2114e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.0885e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.6677e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.2755e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.1895e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1588e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.1279e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 9.7583e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.0458e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 9.4763e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.2461e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.1048e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.0943e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.3322e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.3208e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.4076e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 3ms/step - loss: 0.0156\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 2.0195e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1628e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.7491e-05\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.6305e-05\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.4031e-05\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5423e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.8304e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3280e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.4133e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5652e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.7395e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9060e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.9395e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.4923e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.8413e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.7228e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0847e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0245e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.9060e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.8661e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.4947e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.0585e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.5490e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.5796e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0597e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5021e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.3484e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1998e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.1446e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 4ms/step - loss: 0.0151\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 2.1061e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.0512e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.0881e-05\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 7.3865e-05\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 7.5372e-05\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 8.8408e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 7.8152e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 6.8945e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 7.8764e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.6283e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 7.7172e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.5722e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.6851e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.5254e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.2965e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.2871e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 7.9498e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.3128e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.7999e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.8562e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 9.0441e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 9.3338e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.0577e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.4011e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.0481e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 8.3855e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 1.2089e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.6430e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 7.3947e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 4ms/step - loss: 0.0346\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 5.9880e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.9934e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.4722e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.3684e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.1856e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.0991e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.0908e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 9.5438e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.9296e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.6294e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.7752e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.7474e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.3751e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.1465e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.7865e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9337e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.8338e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.1762e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5333e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5449e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.5572e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.6607e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3851e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.9053e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.2221e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3112e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.2667e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.5400e-05\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.3218e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.0149\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.5616e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.3873e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.5279e-05\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.6681e-05\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.7861e-05\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.8596e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.0272e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.2789e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5214e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.6968e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.1733e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.2995e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.5782e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.3596e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.1686e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 1.1348e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.4613e-05\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.9195e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.2341e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.9779e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.1360e-05\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.0024e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 8.0890e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 9.3556e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 1.2705e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 1.1868e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 1.0023e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 1.0356e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 9.0767e-05\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 3ms/step - loss: 0.0155\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.9708e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.3071e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.0634e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.4716e-05\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.5327e-05\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.1682e-05\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.8549e-05\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.9002e-05\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.5697e-05\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.4911e-05\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.8834e-05\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.4990e-05\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.7967e-05\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.8180e-05\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.5817e-05\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.9755e-05\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.0472e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.5776e-05\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.2251e-05\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.1929e-05\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.3275e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.5076e-05\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.8085e-05\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.2676e-05\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 9.0917e-05\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 8.5108e-05\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 9.7648e-05\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.0993e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 1.3001e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 4ms/step - loss: 0.2507\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.4247e-04\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.2069e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.3941e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.2166e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.2395e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.4897e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.2567e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.9751e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.1311e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.3877e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.4859e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.8912e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.9849e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4229e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.0238e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4848e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6541e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.7342e-04\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.2161e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.7171e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 3.2700e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.7963e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.4663e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.4185e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.1821e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 2.6783e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 3.8292e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6080e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.7245\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0445\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.6084\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.4546e-04\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6181e-04\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 8.1615e-04\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.7345e-04\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.5646e-04\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.6306e-04\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.9691e-04\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9028e-04\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.8555e-04\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 4.6828e-04\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.5805e-04\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.1121e-04\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.7764e-04\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.9144e-04\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.1731e-04\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 7.2274e-04\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.0655e-04\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.7539e-04\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.3832e-04\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 6.6575e-04\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.4559e-04\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.9668e-04\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 5.1004e-04\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 4.9563e-04\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 6.9892e-04\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 7.3863e-04\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 5.6907e-04\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.7241\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0441\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0446\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0451\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0449\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0444\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0446\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0446\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0448\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0441\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0444\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0441\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0446\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0444\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0446\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0455\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0441\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 0.8571\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 1.2756\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0449\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0449\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0453\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0448\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0452\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0446\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0448\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0445\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0448\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0444\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0444\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0455\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0453\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0442\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0446\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0444\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0444\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0446\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 1.0494\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0441\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0446\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0453\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0460\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0475\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0453\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0446\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0445\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0441\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0455\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0467\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0443\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0450\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0455\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0445\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0448\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0457\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 2ms/step - loss: 2.0551\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0446\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0451\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0467\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0458\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0470\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0448\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0444\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0454\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0462\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0457\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0456\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0461\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0451\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0450\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0455\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0443\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0444\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0445\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0442\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0445\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0453\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0440\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0456\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0443\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 1s 3ms/step - loss: 6.2119\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0440\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.0436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the best model out of all combinations"
      ],
      "metadata": {
        "id": "fvBltGfm-fzd"
      },
      "id": "fvBltGfm-fzd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rPGNFqdINTP"
      },
      "source": [
        "## 6) Test your trained classifiers on the Validation set (10 pts)\n",
        "Test your trained classifiers on the validation set and print the mean squared errors.\n"
      ],
      "id": "4rPGNFqdINTP"
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "\n",
        "for model in models:\n",
        "  score = model.evaluate(X_validate, y_validate, verbose=0)  \n",
        "  scores.append(score)\n",
        "  one_layered[model]['score'] = score\n",
        "  print(one_layered[model]['activation'],one_layered[model]['learning_rate'],one_layered[model]['layer1'],\"MSE Score: \", score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmAMvLktAcEI",
        "outputId": "fd626a2e-7a98-43f1-9575-a96f24f956e6"
      },
      "id": "SmAMvLktAcEI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid 0.001 25 MSE Score:  0.00036183500196784735\n",
            "sigmoid 0.001 50 MSE Score:  0.00038931670133024454\n",
            "sigmoid 0.001 100 MSE Score:  0.00035190890775993466\n",
            "sigmoid 0.01 25 MSE Score:  0.0006680361111648381\n",
            "sigmoid 0.01 50 MSE Score:  0.00031313151703216136\n",
            "sigmoid 0.01 100 MSE Score:  0.00048528294428251684\n",
            "sigmoid 0.1 25 MSE Score:  0.00012579838221427053\n",
            "sigmoid 0.1 50 MSE Score:  0.00013945625687483698\n",
            "sigmoid 0.1 100 MSE Score:  0.00030518174753524363\n",
            "relu 0.001 25 MSE Score:  0.0005061730043962598\n",
            "relu 0.001 50 MSE Score:  6.825794844189659e-05\n",
            "relu 0.001 100 MSE Score:  6.558789755217731e-05\n",
            "relu 0.01 25 MSE Score:  0.00011399292998248711\n",
            "relu 0.01 50 MSE Score:  0.00015610178525093943\n",
            "relu 0.01 100 MSE Score:  7.513321907026693e-05\n",
            "relu 0.1 25 MSE Score:  0.0006180982454679906\n",
            "relu 0.1 50 MSE Score:  0.0005088504403829575\n",
            "relu 0.1 100 MSE Score:  0.0004444707010407001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_score_1 = 10000000.0\n",
        "best_model_one_layer = {}\n",
        "\n",
        "for item in one_layered:\n",
        "  a = one_layered[item]\n",
        "  if a['score'] < min_score_1:\n",
        "    best_model_one_layer = item\n",
        "    min_score_1 = a['score']\n",
        "  \n",
        "\n",
        "print(\"Score of the best scored model: \", one_layered[best_model_one_layer]['score'], '\\n')\n",
        "print(\"1-Hidden Layer Model with minimum loss: \", one_layered[best_model_one_layer])"
      ],
      "metadata": {
        "id": "1_5r1-dH1-fN",
        "outputId": "a4bbe41c-63e8-4ea2-f2c5-3322703dfdd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1_5r1-dH1-fN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score of the best scored model:  6.558789755217731e-05 \n",
            "\n",
            "1-Hidden Layer Model with minimum loss:  {'model': <keras.engine.sequential.Sequential object at 0x7f3ff9a48850>, 'activation': 'relu', 'layer1': 100, 'learning_rate': 0.001, 'score': 6.558789755217731e-05}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9noUcsDJH1Hz",
        "outputId": "5cbfa7db-86e0-4f26-a3e4-13a2b0c545cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scores_two = []\n",
        "\n",
        "for model in models_two:\n",
        "  score = model.evaluate(X_validate, y_validate, verbose=0)\n",
        "  scores_two.append(score)\n",
        "  two_layered[model]['score'] = score\n",
        "  print(two_layered[model]['activation'],two_layered[model]['learning_rate'],two_layered[model]['layer1'],two_layered[model]['layer2'],\"MSE Score: \", score)\n",
        "  \n"
      ],
      "id": "9noUcsDJH1Hz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid 0.001 25 25 MSE Score:  0.00032741163158789277\n",
            "sigmoid 0.001 25 50 MSE Score:  0.00032446306431666017\n",
            "sigmoid 0.001 25 100 MSE Score:  0.00033768106368370354\n",
            "sigmoid 0.001 50 25 MSE Score:  0.00031512408168055117\n",
            "sigmoid 0.001 50 50 MSE Score:  0.0003219610371161252\n",
            "sigmoid 0.001 50 100 MSE Score:  0.0003967750817537308\n",
            "sigmoid 0.001 100 25 MSE Score:  0.00041346819489263\n",
            "sigmoid 0.001 100 50 MSE Score:  0.00036869768518954515\n",
            "sigmoid 0.001 100 100 MSE Score:  0.00033728653215803206\n",
            "sigmoid 0.01 25 25 MSE Score:  0.00029342962079681456\n",
            "sigmoid 0.01 25 50 MSE Score:  0.00020361946371849626\n",
            "sigmoid 0.01 25 100 MSE Score:  0.0002670257235877216\n",
            "sigmoid 0.01 50 25 MSE Score:  0.0002399661170784384\n",
            "sigmoid 0.01 50 50 MSE Score:  0.0003942179901059717\n",
            "sigmoid 0.01 50 100 MSE Score:  0.00021896559337619692\n",
            "sigmoid 0.01 100 25 MSE Score:  0.0004476413887459785\n",
            "sigmoid 0.01 100 50 MSE Score:  0.0004406751540955156\n",
            "sigmoid 0.01 100 100 MSE Score:  0.0005425632116384804\n",
            "sigmoid 0.1 25 25 MSE Score:  0.00033667145180515945\n",
            "sigmoid 0.1 25 50 MSE Score:  6.517956353491172e-05\n",
            "sigmoid 0.1 25 100 MSE Score:  0.0007099964423105121\n",
            "sigmoid 0.1 50 25 MSE Score:  0.00028804870089516044\n",
            "sigmoid 0.1 50 50 MSE Score:  0.00011367069237167016\n",
            "sigmoid 0.1 50 100 MSE Score:  0.0002961841528303921\n",
            "sigmoid 0.1 100 25 MSE Score:  0.00023705755302216858\n",
            "sigmoid 0.1 100 50 MSE Score:  9.449138451600447e-05\n",
            "sigmoid 0.1 100 100 MSE Score:  0.00040596621693111956\n",
            "relu 0.001 25 25 MSE Score:  8.615724800620228e-05\n",
            "relu 0.001 25 50 MSE Score:  7.015091978246346e-05\n",
            "relu 0.001 25 100 MSE Score:  5.8343037380836904e-05\n",
            "relu 0.001 50 25 MSE Score:  5.936900561209768e-05\n",
            "relu 0.001 50 50 MSE Score:  6.369883340084925e-05\n",
            "relu 0.001 50 100 MSE Score:  6.011507866787724e-05\n",
            "relu 0.001 100 25 MSE Score:  6.631916767219082e-05\n",
            "relu 0.001 100 50 MSE Score:  6.500326708192006e-05\n",
            "relu 0.001 100 100 MSE Score:  7.17694201739505e-05\n",
            "relu 0.01 25 25 MSE Score:  7.987397111719474e-05\n",
            "relu 0.01 25 50 MSE Score:  8.101195999188349e-05\n",
            "relu 0.01 25 100 MSE Score:  0.00013444555224850774\n",
            "relu 0.01 50 25 MSE Score:  0.000248124822974205\n",
            "relu 0.01 50 50 MSE Score:  0.0002315555902896449\n",
            "relu 0.01 50 100 MSE Score:  0.00012540446186903864\n",
            "relu 0.01 100 25 MSE Score:  6.213751476025209e-05\n",
            "relu 0.01 100 50 MSE Score:  6.730486347805709e-05\n",
            "relu 0.01 100 100 MSE Score:  7.818433368811384e-05\n",
            "relu 0.1 25 25 MSE Score:  0.0003114185237791389\n",
            "relu 0.1 25 50 MSE Score:  0.048676230013370514\n",
            "relu 0.1 25 100 MSE Score:  0.0007237415993586183\n",
            "relu 0.1 50 25 MSE Score:  0.048384927213191986\n",
            "relu 0.1 50 50 MSE Score:  0.04863313212990761\n",
            "relu 0.1 50 100 MSE Score:  0.0501435361802578\n",
            "relu 0.1 100 25 MSE Score:  0.05044826120138168\n",
            "relu 0.1 100 50 MSE Score:  0.049194131046533585\n",
            "relu 0.1 100 100 MSE Score:  0.048378851264715195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_score_2 = 10000000.0\n",
        "best_model_two_layer = {}\n",
        "\n",
        "for item in two_layered:\n",
        "  a = two_layered[item]\n",
        "  if a['score'] < min_score_2:\n",
        "    best_model_two_layer = item\n",
        "    min_score_2 = a['score']\n",
        "  \n",
        "\n",
        "print(two_layered[best_model_two_layer]['score'], '\\n')\n",
        "print(\"2-Hidden Layer Model with minimum loss: \", two_layered[best_model_two_layer])"
      ],
      "metadata": {
        "id": "rnetjdvkGd1R",
        "outputId": "5aac244d-f3da-40ed-88d6-37b9373bdc6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rnetjdvkGd1R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.8343037380836904e-05 \n",
            "\n",
            "2-Hidden Layer Model with minimum loss:  {'model': <keras.engine.sequential.Sequential object at 0x7f3fe0840590>, 'activation': 'relu', 'layer1': 25, 'layer2': 100, 'learning_rate': 0.001, 'score': 5.8343037380836904e-05}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compare = (lambda x1, x2: best_model_one_layer if x1 < x2 else best_model_two_layer)\n",
        "\n",
        "best_model = compare(min_score_1,min_score_2)\n",
        "\n",
        "def checkKey(dict, key):\n",
        "    if key in dict:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "inOne = checkKey(one_layered, best_model)\n",
        "inTwo = checkKey(two_layered, best_model)\n",
        "\n",
        "\n",
        "best_model_content = {}\n",
        "if inOne == 1:\n",
        "  best_model_content = one_layered[best_model]\n",
        "  print(\"Best model is a 1-hidden layer NN: \\n\")\n",
        "else:\n",
        "  best_model_content = two_layered[best_model]\n",
        "  print(\"Best model is a 2-hidden layer NN: \\n\")\n",
        "\n",
        "best_model_content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmGrdk-bT0hw",
        "outputId": "d0eb0adb-9624-4b06-90b6-3d1517e07957"
      },
      "id": "cmGrdk-bT0hw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model is a 2-hidden layer NN: \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'layer1': 25,\n",
              " 'layer2': 100,\n",
              " 'learning_rate': 0.001,\n",
              " 'model': <keras.engine.sequential.Sequential at 0x7f3fe0840590>,\n",
              " 'score': 5.8343037380836904e-05}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mojk_4Q9JQkR"
      },
      "source": [
        "## 7) Test your classifier on Test set (10 pts)\n",
        "\n",
        "- Load test data\n",
        "- Apply same pre-processing as training data (encoding categorical variables, scaling)\n",
        "- Predict the labels of testing data **using the best model that you have selected according to your validation results** and report the mean squared error. "
      ],
      "id": "mojk_4Q9JQkR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f3558e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "2e5d000a-1ac7-4ecb-f620-b7c3ef10ef6e"
      },
      "source": [
        "# test results\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "test_df.head(10)"
      ],
      "id": "5f3558e8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sqmtrs  nrooms   view crime_rate         price\n",
              "0     349       3  south       high  8.365535e+05\n",
              "1     169       1   west       high  5.127416e+05\n",
              "2     233       3  south       high  6.638806e+05\n",
              "3     340       4  north        low  1.000086e+06\n",
              "4     199       2   east        low  7.450151e+05\n",
              "5     332       1   east       high  7.740171e+05\n",
              "6     294       3   west        low  9.132634e+05\n",
              "7     111       3   east        low  5.861116e+05\n",
              "8     310       5  north        low  1.012929e+06\n",
              "9     307       4   west        low  9.715327e+05"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0343a512-2924-4ffd-8900-cf1ef2e6379e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sqmtrs</th>\n",
              "      <th>nrooms</th>\n",
              "      <th>view</th>\n",
              "      <th>crime_rate</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>349</td>\n",
              "      <td>3</td>\n",
              "      <td>south</td>\n",
              "      <td>high</td>\n",
              "      <td>8.365535e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>169</td>\n",
              "      <td>1</td>\n",
              "      <td>west</td>\n",
              "      <td>high</td>\n",
              "      <td>5.127416e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>233</td>\n",
              "      <td>3</td>\n",
              "      <td>south</td>\n",
              "      <td>high</td>\n",
              "      <td>6.638806e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>340</td>\n",
              "      <td>4</td>\n",
              "      <td>north</td>\n",
              "      <td>low</td>\n",
              "      <td>1.000086e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>199</td>\n",
              "      <td>2</td>\n",
              "      <td>east</td>\n",
              "      <td>low</td>\n",
              "      <td>7.450151e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>332</td>\n",
              "      <td>1</td>\n",
              "      <td>east</td>\n",
              "      <td>high</td>\n",
              "      <td>7.740171e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>294</td>\n",
              "      <td>3</td>\n",
              "      <td>west</td>\n",
              "      <td>low</td>\n",
              "      <td>9.132634e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>111</td>\n",
              "      <td>3</td>\n",
              "      <td>east</td>\n",
              "      <td>low</td>\n",
              "      <td>5.861116e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>310</td>\n",
              "      <td>5</td>\n",
              "      <td>north</td>\n",
              "      <td>low</td>\n",
              "      <td>1.012929e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>307</td>\n",
              "      <td>4</td>\n",
              "      <td>west</td>\n",
              "      <td>low</td>\n",
              "      <td>9.715327e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0343a512-2924-4ffd-8900-cf1ef2e6379e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0343a512-2924-4ffd-8900-cf1ef2e6379e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0343a512-2924-4ffd-8900-cf1ef2e6379e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "test_df = pd.get_dummies(test_df)\n",
        "\n",
        "# scale the features between 0-1\n",
        "msc = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "scaled_test = msc.fit_transform(test_df)\n",
        "\n",
        "scaled_test_df = pd.DataFrame(scaled_test, columns=test_df.columns.values)\n",
        "\n",
        "# Define X:\n",
        "X_test = scaled_test_df.drop(columns=['price'])\n",
        "\n",
        "# Define y:\n",
        "y_test = scaled_test_df[['price']]\n",
        "\n"
      ],
      "metadata": {
        "id": "HnpxS0caXdEO"
      },
      "id": "HnpxS0caXdEO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = best_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"MSE testing score for the best model: \", score, \"\\n\")\n",
        "print(\"MSE testing parameters for the best model: \")\n",
        "best_model_content['score'] = score\n",
        "best_model_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EezxAEhnYIIX",
        "outputId": "6f5b44eb-5c7e-4372-d577-7ecfcdb92986"
      },
      "id": "EezxAEhnYIIX",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE testing score for the best model:  0.0004797478031832725 \n",
            "\n",
            "MSE testing parameters for the best model: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'layer1': 25,\n",
              " 'layer2': 100,\n",
              " 'learning_rate': 0.001,\n",
              " 'model': <keras.engine.sequential.Sequential at 0x7f3fe0840590>,\n",
              " 'score': 0.0004797478031832725}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg0mDfdNJgrd"
      },
      "source": [
        "##8) Report Your Results (10 pts)\n",
        "\n",
        "**Notebook should be RUN:** As training and testing may take a long time, we may just look at your notebook results without running the code again; so make sure **each cell is run**, so outputs are there.\n",
        "\n",
        "**Report:** Write an **1-2 page summary** of your approach to this problem **as indicated below**. \n",
        "\n",
        "**Must include statements such as those below:**\n",
        "**(Remove the text in parentheses, below, and include your own report)**\n",
        "\n",
        "**Problem Definition**: House price prediction problem is a regression problem where as inputs there exist area of the houses, number of rooms, view of the house and crime rates in the neighborhood that the house is located and output is the price of the given house according to the above stated parameters. In order to solve this problem, a regression model can be built. Therefore, I build Neural Network regression models with 1-Hidden Layers and 2-Hidden Layers with different activation functions and layer size parameters.\n",
        "\n",
        "**Train/val/test sets, size and how split**: As the training set, I had a data set with 4800 examples with 5 attributes such as number of rooms, square meters, view, crime rate and price of the house. I used 10% of the training set as the validation set and trained my models with the remaining 4320 (90%) examples. For the testing set, I had a data set with 1200 examples with 4 attributes which are the same as the training set except the price since it is the parameter that I would predict.\n",
        "\n",
        " **Feature extraction and preprocessing**: Attributes view and crime_rates were categorical variables and in order to efficiently process them I used get_dummies function of the pandas library and turned them into numerical values. Also, in order to employ the data efficiently, I used minmax scaler and scaled all variables between 0 and 1.\n",
        "\n",
        "\n",
        "**Add your observations as follows** (keep the questions for easy grading/context) in the report part of your notebook.\n",
        "\n",
        "**Observations**\n",
        "\n",
        "- Try a few learning rates for N=25 hidden neurons,  train for the indicated amount of epochs. Comment on what happens when learning rate is large or small? What is a good number/range for the learning rate?\n",
        "\n",
        "1-Hidden Layer w/ 25 nodes:\n",
        "\n",
        "sigmoid 0.001 25 MSE Score:  0.00036183500196784735\n",
        "\n",
        "sigmoid 0.01  25 MSE Score:  0.0006680361111648381\n",
        "\n",
        "sigmoid 0.1   25 MSE Score:  0.00012579838221427053\n",
        "\n",
        "Relu    0.001 25 MSE Score:  0.0005061730043962598\n",
        "\n",
        "Relu    0.01  25 MSE Score:  0.00011399292998248711\n",
        "\n",
        "Relu    0.1   25 MSE Score:  0.0006180982454679906\n",
        "\n",
        "I observed that the optimal score (min loss for the cost function) occurs with the learning rate around 0.01 for a NN which has 1-hidden layer and ReLU activation function for models that have 25 nodes. Also, I tried this learning rate along with other given rates on models which have 1 or 2 hidden layers with 'RELU' or 'Sigmoid' activation functions and node sizes vary around 25, 50, 100 nodes along with learning rates 0.001 and 0.1. Consequently, I found that the best performing model has two layers with 0.001 learning rate, RELU activation function and 25 nodes on first layer and 100 nodes in second layer along with the best performing 1-hidden layered model also have 0.001 learning rate.\n",
        "\n",
        "\n",
        "- Use that learning rate and vary the number of hidden neurons for the given values and try the indicated number of epochs. Give the validation mean squared errors for different approach and meta-parameters tried **in a table** and state which one you selected as your model. How many hidden neurons give the best model? \n",
        "\n",
        "| Num hid layers | #Layer 1 | #Layer 2 | Learning Rate | Activation Func. | MSE Score |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| 2 | 25 | 100 | 0.001 | ReLU | 5.8343037380836904e-05 |\n",
        "| 2 | 25 | 100 | 0.001 | Sigmoid | 0.00033768106368370354 |\n",
        "| 1 | 100 | - | 0.001 | ReLU | 6.558789755217731e-05 |\n",
        "| 1 |100 | - | 0.001 | Sigmoid | 0.00035190890775993466|\n",
        "|...|\n",
        "| 1 | 25 | - | 0.001 | ReLU | 0.0005061730043962598 |\n",
        "| 1 | 50 | - | 0.001 | ReLU | 6.825794844189659e-05 |\n",
        "| 2 | 25 | 50 | 0.001 | ReLU | 7.015091978246346e-05 |\n",
        "| 2 | 25 | 25 | 0.001 | ReLU | 8.615724800620228e-05 |\n",
        "| 2 | 50 | 100 | 0.001 | ReLU | 6.011507866787724e-05|\n",
        "| 2 | 100 | 100 | 0.001 | ReLU | 7.17694201739505e-05 |\n",
        "|...|\n",
        "|Test Score|\n",
        "| 2 | 25 | 100 | 0.001 | ReLU | 0.0004797478031832725 |\n",
        "\n",
        "Best result for 1-hidden layered model is 6.558789755217731e-05 with 100 nodes however, best result overall is 5.8343037380836904e-05 with a 2-hidden layered model with 25 nodes in hidden layer 1 and 100 nodes with hidden layer 2. Since it is the best performing model (gives the minimum loss), I selected the 2-hidden layered (25,100) with ReLU function as my model to evaluate the test set.\n",
        "\n",
        "- State  what your test results are with the chosen approach and meta-parameters: \n",
        "\n",
        "\"We have obtained the best results on the validation set with the two-hidden layered NN approach using a value of 0.001 for learning_rate parameter, 25 nodes on first hidden layer, 100 nodes on second hidden layer and RELU for activation function. The result of this model on the test data gave MSE 0.0004797478031832725 as the score.\"\" \n",
        "\n",
        "- How slow is learning? Any other problems?\n",
        "\n",
        "Training 1-hidden layer models took ~3 minutes while training 2-hidden layer models took ~8-9 minutes but in return for long training time 2-hidden layer models performed better on validations. Also, models with lower learning rates took more time to train. Additionally, validation and testing took under 20 seconds. I did not encounter any problems.\n",
        "\n",
        "- Any other observations (not obligatory)\n",
        "\n",
        " You can add additional visualization as separate pages if you want, think of them as appendix, keeping the summary to 1-2-pages.\n",
        "\n"
      ],
      "id": "Qg0mDfdNJgrd"
    }
  ]
}